{
\abnormalparskip{0pt}
\chapter{Experiments}
\label{cha:experiments}
}

This chapter describes and discusses the experiments that have been performed in
relation to the new implementation.

All experiments have been executed on computer with $8 \times$
Intel\textsuperscript{\textregistered} Xeon\textsuperscript{\textregistered} CPU
E5-2630L at $2.00$ GHz and with $16$ GB RAM. Furthermore all tests were executed
using version $1.4.2$ of Go\footnote{A newer version (1.5) which improves the performance of
  the language due to more efficient garbage collection was released after the
  experiments had been conducted.}. In the experiments the used methods are
named as seen in \cref{tab:method-names}.

\begin{table}[htbp]
  \centering
  \begin{tabular}{cp{9cm}}
    \toprule
    Method                & Description                                                                                                                                      \\
    \midrule
    \texttt{Simple}       & New implementation using the analytical method. Implemented in Go.                                                                               \\
    \texttt{SimpleSort}   & New implementation using the analytical method and with terminal sorting. Implemented in Go.                                                     \\
    \texttt{SmithNew}     & New implementation using \citeauthor{smith1992}'s iteration. Implemented in Go.                                                                  \\
    \texttt{SmithNewSort} & New implementation using \citeauthor{smith1992}'s iteration and with terminal sorting. Implemented in Go.                                        \\
    \texttt{SmithOld}     & Original implementation by \textcite{smith1992}, only slightly modified to fix the bug described in \cref{sec:if-clause-when}. Implemented in C. \\
    \bottomrule
  \end{tabular}
  \caption[Naming of methods]{The table shows the used naming of the methods
    used during the experiments.\label{tab:method-names}}
\end{table}

In general the experiments performed, relates to either
correctness or performance of the implementation. The correctness has been
measured by comparing a set of instances with the results found by the
GeoSteiner program. The performance experiments is divided into experiments
regarding the speed of the methods, the number of trees which are optimized, and
the number of iterations being run. 

\section{Correctness}
\label{sec:correctness}

To test the correctness of the new implementation $150$ random cube instances
with $n = 10 \ldots 12$ and $d = 2$ has been run. The cube instances are the
same as used by \textcite{fonseca2014}, which can also be found at
\url{https://github.com/DIKU-Steiner/MPC15/tree/master/experiments/Correctness/Instances}.
The terminals of the instances are randomly distributed in a unit cube.

The experiments were run for all of the methods in \cref{tab:method-names},
except \texttt{SmithOld}. The instances we also run using the official
GeoSteiner implementation\footnote{The implementation can be found at downloaded
  at \url{http://geosteiner.com}}.

After all instances were completed, the results of the new implementation were
compared with the results of the GeoSteiner program. This showed that the
analytical solution, both with and without terminals sorting, in a few instances
gave sub-optimal \acp{smt}\footnote{By sub-optimal we mean that the length of
  the tree found is longer than the length of the optimal \ac{smt}. This may also
  mean that the topology is different.}. These and the difference to the optimal
\ac{smt} found by GeoSteiner can be found in \cref{tab:correctness-errors}.

\begin{table}[htbp]
  \centering
  \begin{tabular}{ccc}
    \toprule
    Instance           & Method              & Diff       \\
    \midrule
    cube\_n12\_d2\_s27 & \texttt{Simple}     & $+0.170\%$ \\
    cube\_n12\_d2\_s49 & \texttt{Simple}     & $+0.295\%$ \\
    cube\_n10\_d2\_s42 & \texttt{SimpleSort} & $+0.015\%$ \\
    cube\_n12\_d2\_s26 & \texttt{SimpleSort} & $+0.228\%$ \\
    cube\_n12\_d2\_s43 & \texttt{SimpleSort} & $+0.292\%$ \\
    cube\_n12\_d2\_s49 & \texttt{SimpleSort} & $+0.295\%$ \\
    \bottomrule
  \end{tabular}
  \caption[Sub-optimal results in correctness test]{The table shows the
    instances in which some method gave sub-optimal results, and the difference
    in percent to the optimal \acp{smt} found by the GeoSteiner
    program.\label{tab:correctness-errors}}
\end{table}

As can be seen \texttt{Simple} gave sub-optimal results in $2 (1.3\%)$
instances, and \texttt{SimpleSort} in $4 (2.7\%)$ instances. Neither
\texttt{SmithNew} or \texttt{SmithNewSort} gave any errors.

When inspecting the \acp{smt} generated by the simple method in the sub-optimal
instances, it was clear, that the method in these cases indeed gave different
topologies from the topologies found by the GeoSteiner program.

The reason for this, I believe, can be traced back to two things: the
if-clauses in the implementation used when optimizing, and the possibility that
the error function defined by \citeauthor{smith1992} is faulty.

\begin{figure}[htbp]
  \begin{c-code}
    ITER:
    q = length();
    r = error();
    if ( q - r < STUB) {
      if (r > 0.005*q) {
        optimize(0.0001*r/NUMSITES);
        goto ITER;
      }
      /* Truncated code.
         Pushes topology and length to stack.
         Continue working with the topology and its descendants */
    }
    /* Continue to next topology vector of same length,
       if we have no been in the outer if-clause then all
       descendants of the current topology vector is 
       effectively pruned as we have not stored it on the stack. */
  \end{c-code}
  \captionof{listing}[Loop condition for pruning topologies]{The outer if-clause
    decides whether we prune a topology or not. This is applied before the
    topology is optimized to its \acs{rmt}, which significantly speeds up the
    program. But whether this is allowed is unclear. The code snippet is from
    \citeauthor{smith1992}'s implementation, given in \textcite{smith1992}. The new
    implementation in Go uses the same two
    conditions.\label{fig:loop-condition-pruning}}
\end{figure}

Consider the code snippet in \cref{fig:loop-condition-pruning} or equivalently
the flowchart in \cref{fig:flowchart}, which is from the original implementation
found in \textcite{smith1992}. What happens in the snippet is the following:
before any optimization iterations has taken place, the tree length and error of
the tree is calculated (afterwards it also occurs as it happens just after
jumping to the label from the goto). A check (the first if-clause) whether the
tree length minus the error is lower than the upper bound ($q-r <
\textit{STUB}$) is then performed. If the check yields false, the main loop
continues without pushing the topology vector to the stack described in
\cref{sec:order-build-optim}. This means that any descendant of that topology
vector will not be optimized, i.e.\ they are pruned. If the check yields true,
the program goes to the second if-clause which checks if the error is greater
than $0.005 \cdot q$. If the second check yields true, the tree is optimized,
and the program return to the \texttt{ITER} label. If it yields false, the
program continues on, within the first if-clause, and eventually push the
topology vector to the stack.

\begin{figure}[htbp]
  \centering
  \input{gfx/tikz/flowchart.tikz}
  \caption[Flowchart of loop condition]{The flowchart shows the structure of the
    he code from \cref{fig:loop-condition-pruning}. \fbox{1} = Reject the
    topology and its descendant. \fbox{2} = Error is sufficiently small. Push on
  stack for future expansion or fine tuning.\label{fig:flowchart}}
\end{figure}

The structure just described means that we can both discard a topology before
optimizing it, or after optimizing some number of iterations. This
significantly speeds up the program, in contrast to optimizing the topology to
its \ac{rmt} and then deciding whether it must be pruned or not (by comparing
its length to the upper bound). The new
implementation therefore retained this structure.

However as described in \cref{sec:loop-condition-when-1} there seems to be no
direct relation between the tree length and error of the tree. Also as described in
\cref{sec:choice-error-funct} it is unclear whether the error function is
even correct. Thus both of these if-clauses are a bit sketchy.

\begin{figure}[htbp]
  \centering
  \begin{subfigure}[t]{0.4\textwidth}
    \includegraphics[width=\textwidth]{gfx/tikz/upperbound-2}
    \caption{Example where subtracting the error from the tree
      length yields a length shorter than the current upper bound. In this case
      the program would continue to optimize on the topology, and there is no
      risk of prematurely pruning it.\label{fig:upperbound-2}}
  \end{subfigure}\hspace{1em}
  \begin{subfigure}[t]{0.4\textwidth}
    \includegraphics[width=\textwidth]{gfx/tikz/upperbound-1}
    \caption{Example where subtracting the error from the tree length yields a
      length greater than the current upper bound. If it is not always the case
      that $q-r$ is shorter than or equal to the tree length of $\ac{rmt}$
      $q^\ast$, this could result in the topology being pruned being pruned
      prematurely.\label{fig:upperbound-1}}
  \end{subfigure}
  \caption[Upper bounds, 1 and 2]{The possible situations when reaching the
    first if-clause.\label{fig:upperbound-1-2}}
\end{figure}

Consider the first if-clause. It assumes that subtracting the current error $r$
from the current tree length $q$, will always yield something which is lower
than or equal to the length of the \ac{rmt} of the topology $q^\ast$ (seen in
\cref{fig:upperbound-2}). If this is not the case, then it could be possible to
get a tree which if optimized would be shorter than the current upper bound, but
where subtracting the current error from the current tree length would not be
shorter than the current upper bound (seen in \cref{fig:upperbound-1}). This
could result in a topology being thrown away even if it should have actually
been kept. Furthermore the possible situations after optimizing the topology is
shown in \cref{fig:upperbound-3-4}.

To test the impact of the first if-clause the instances were run again where the
condition of the first if-clause was changed to $q - 10 \cdot r <
\textit{STUB}$. The observed result that some of the instances which before gave
sub-optimal results were solved to optimality, while other new ones gave
sub-optimal results. These can be seen in \cref{tab:correctness-errors-4}. As
can be seen \texttt{Simple} and \texttt{SimpleSort} were still the only methods
to give sub-optimal results.

\begin{table}[htbp]
  \centering
  \begin{tabular}{ccc}
    \toprule
    Instance           & Method              & Diff       \\
    \midrule
    cube\_n11\_d2\_s9  & \texttt{SimpleSort} & $+0.262\%$ \\
    cube\_n12\_d2\_s12 & \texttt{Simple}     & $+1.405\%$ \\
    cube\_n12\_d2\_s43 & \texttt{SimpleSort} & $+0.292\%$ \\
    cube\_n12\_d2\_s9  & \texttt{SimpleSort} & $+0.214\%$ \\
    \bottomrule
  \end{tabular}
  \caption[Sub-optimal results with condition $q - 10 \cdot r < \textit{STUB}$]{
    Changing the condition of the first if-clause to $q - 10 \cdot r <
    \textit{STUB}$ causes the number of sub-optimal results drop to $4$.
    However some of these are were not sub-optimal before the
    change.\label{tab:correctness-errors-4}}
\end{table}

The instances which were not solved optimally before but were after the change,
seem to indicate that this condition indeed is partly to blame for the
sub-optimality. The reason that new instances suddenly gave sub-optimal results,
I believe, is because these instances now explore topologies which before were
discarded.

\begin{figure}[htbp]
  \centering
  \begin{subfigure}[t]{0.4\textwidth}
    \includegraphics[width=\textwidth]{gfx/tikz/upperbound-3}
    \caption{Example where optimizing the tree results in a new shorter tree length,
      but where the error is still large enough that $q-r$ stays below the upper
      bound. In this case we would proceed to either optimize the topology, or
      put it on the stack, depending on the what the second if-clause
      yields.\label{fig:upperbound-3}}
  \end{subfigure}\hspace{1em}
  \begin{subfigure}[t]{0.4\textwidth}
    \includegraphics[width=\textwidth]{gfx/tikz/upperbound-4}
    \caption{Example where optimizing the tree results in a new shorter tree length,
      and the error becomes small that $q-r$ is longer than the upper bound. In
      this case we prune the topology and all its descendants. If $q-r$ is
      always less than or equal to the length of the \ac{rmt} of the topology
      this is correct. If this is however not the case this could result in
      premature pruning.\label{fig:upperbound-4}}
  \end{subfigure}
  \caption[Upper bounds, 3 and 4]{The possible situations when optimizing a
    topology.\label{fig:upperbound-3-4}}
\end{figure}

Now consider the second if-clause. This assumes two things, firstly that the
size of the error is proportional to the tree length, and secondly that when the
error for the entire tree is low that the tree entire tree then optimal. The
first assumption does have some merit. If one looks at the error function, as it
is defined in \cref{eq:28} it is clear that if we have longer edges, they will
contribute more than shorter edges. Whether there is a direct relation between
the error and the tree length is however still unclear. The second assumption
however faces some problems in the new implementation. This assumes that we will
not hit a a situation in which most of the tree is optimal, but e.g.\ a single
Steiner point contributes a large error and is at a sub-optimal placement. This
is a problem, as a single Steiner point at a wrong position can propagate
changes throughout the tree when it is optimized. It may therefore be, that the
tree is not at all optimal, and that we risk stopping prematurely.

\begin{table}[htbp]
  \centering
  \begin{tabular}{ccc}
    \toprule
    Instance           & Method              & Diff       \\
    \midrule
    cube\_n12\_d2\_s27 & \texttt{Simple}     & $+0.170\%$ \\
    cube\_n12\_d2\_s49 & \texttt{Simple}     & $+0.295\%$ \\
    cube\_n10\_d2\_s42 & \texttt{SimpleSort} & $+0.015\%$ \\
    cube\_n12\_d2\_s26 & \texttt{SimpleSort} & $+0.228\%$ \\
    cube\_n12\_d2\_s38 & \texttt{SimpleSort} & $+0.071\%$ \\
    cube\_n12\_d2\_s43 & \texttt{SimpleSort} & $+0.291\%$ \\
    cube\_n12\_d2\_s49 & \texttt{SimpleSort} & $+0.295\%$ \\
    \bottomrule
  \end{tabular}
  \caption[Sub-optimal results with condition $r > 0.0005 \cdot q$]{Changing
    the condition of the second if-clause to $r > 0.0005 \cdot q$ causes the
    number of sub-optimal results increase to $7$.\label{tab:correctness-errors-2}}
\end{table}

This may not have been a problem in the original implementation which rebuilt the
topology every time it was changed, however the new implementation does not
rebuild the entire topology, but reuses the already found placements when
splitting the topology. Thus the issue might be magnified by this new approach. 

A question that emerges is why the issue with sub-optimality only occurs when
using \texttt{Simple} and \texttt{SimpleSort} but not when using \texttt{SmithNew} and
\texttt{SmithNewSort}. I.e.\ why does the analytical solution show this issue,
but not \citeauthor{smith1992}'s iteration?

The reason for this, I believe, is that the analytical solution when it runs in
general obtains much lower error-figures than \citeauthor{smith1992}'s
iteration. I therefore believe that the issue exists for both iteration methods,
but is magnified and therefore only seen when using the analytical solution.

The potential problem is summed up by \cref{fig:upperbound-5}. We may have some
topology which has been optimized to have a very low error, this is particularly
likely using the analytical solution which attains very low error-figures. Upon
splitting the topology and adding the next terminal and a new Steiner point, the
error is raised. However because the error of the rest of the tree is very low,
the error is not raised enough for the new $q-r$ to stay below the current
upper bound, and as such the topology will be pruned even though optimizing it
may result in the new Steiner point moving and propagating changes throughout
the tree, which could have resulted in a new upper bound.

The problem could also escalate over the course of a few of these situations in
a row, where one adds a terminal, but does not optimize as the error continues
to stay below the threshold.

\begin{figure}[htbp]
  \centering
  \includegraphics[width=.4\textwidth]{gfx/tikz/upperbound-5}
  \caption[Upper bounds, 5]{Splitting a topology raises the error of the tree.
    However if the error does not go up enough for the tree length minus the error to
    stay below the upper bound, the topology will be pruned. This situation
    again assumes that $q-r$ will also less than or equal to the length of the
    \ac{rmt} for the topology. If this is not the case, it could be thought that
    this situation could also occur when the tree should no be pruned, but
    because of a low error on most of the tree it will be pruned
    prematurely.\label{fig:upperbound-5}}
\end{figure}

To test the impact of the second if-clause the instances were run with the
condition of the clause change to $r > 0.05 \cdot q$ and $r > 0.0005 \cdot q$.
The sub-optimal results from these runs can be found in
\cref{tab:correctness-errors-2,tab:correctness-errors-3}. As can be seen, allowing a
higher error gives fewer sub-optimal results, whereas setting the error even
lower raises the number of sub-optimal instances produced by the analytical
solution.

\begin{table}[htbp]
  \centering
  \begin{tabular}{ccc}
    \toprule
    Instance           & Method              & Diff       \\
    \midrule
    cube\_n12\_d2\_s27 & \texttt{Simple}     & $+0.170\%$ \\
    cube\_n12\_d2\_s43 & \texttt{SimpleSort} & $+0.292\%$ \\
    \bottomrule
  \end{tabular}
  \caption[Sub-optimal results with condition $r > 0.05 \cdot q$]{Changing
    the condition of the second if-clause to $r > 0.05 \cdot q$ causes the
    number of sub-optimal results drop to $2$.\label{tab:correctness-errors-3}}
\end{table}

These observations seem to align with the before described problems.
Consider allowing a higher error in the second if-clause. This would cause the
method to halt earlier in the optimization process, and thus the chance of $q-r$
being lower than the upper bound would probably be better, as we would
less often hit a situation where most of the tree has very low error and only a
single Steiner point has high error. However lowering the allowed error would
cause the program to further optimize the trees, which would further magnify the
problem where all but one Steiner point has very low error.

Further raising the error allowed in the second if-clause to $r > 0.5 \cdot q$
resulted in sub-optimal results being observed across all four of the tested
methods. This is due to the fact the we at this point have raised the error so
much that the optimal trees cannot be obtained in all situations. This also
shows that we cannot simply raise the allowed error for the entire tree to
ensure we will not get sub-optimal results, as it will have to walk a tightrope
between sub-optimality due to to high errors, or sub-optimality due to the
previous described issues.

To correct this problem I believe one would have to do two things. Firstly,
before deciding whether to prune a topology and its descendants one would have
to optimize the tree until it was the \ac{rmt}, i.e.\ drop the condition $q-r <
\textit{STUB}$, and instead optimize until we have the \ac{rmt} and then simply
check $q < \textit{STUB}$, or perhaps $q - \epsilon < \textit{STUB}$ where
$\epsilon$ would be some very small positive number. This would prevent pruning
of topologies prematurely. Secondly, at least when using the analytical solution
(\textit{Simple} and \textit{SimpleSort}) the second if-clause should not look
at the error of the entire tree, but instead at the error of each individual
Steiner point. This would prevent the situation where most of tree has an error
of zero, and one point contributes most of the error. This approach might also
be the correct one for \textit{SmithNew} and \textit{SmithNewSort} as they also, in
contrast to \textit{SmithOld}, do not re-position the already placed Steiner
points when splitting the topology (due to the new method were we can split and
restore a topology, in contrast to the original method where one had to rebuild the
tree from the topology vector every time it was changed).

As the issue was first discovered during the experiments, the current
implementation does not fix it. I however believe this could be done using the
changes described above. It is however unclear how much this would affect the
run-time of the program.

However I do not believe it invalidates the performance data completely, as the
number of sub-optimal trees in the correctness test, was still very low, and the
sub-optimality of these trees also was relatively low.

\section{Performance}
\label{sec:performance}

To test the performance of the implementation the test sets in
\cref{tab:test-sets} have been run for all of the methods described in
\cref{tab:method-names}. The \textit{Carioca} set is from the 2014 DIMACS
challenge, the \textit{Iowa} set is from \textcite{fampa2008}, \textit{Cube} and
\textit{Sausage} are both from \textcite{fonseca2014}. The \textit{Cube} set is
a set of randomly generated instances which has the terminals of each instance
distributed randomly in a unit cube. The \textit{Sausage} set consists of
$d$-sausages, which are linear concatenations of regular $d$-simplices. these
have the lowest currently known Steiner ratio in dimensions $3$ and
up~\cite{smith1995}.

\begin{table}[htbp]
  \centering
  \begin{tabular}{ccccc}
    \toprule
    Set     & Dimensions       & Terminals             & Set size & Point configuration \\
    \midrule
    Carioca & $d = 3 \ldots 5$ & $n = 11 \ldots 16$    & $90$     & Random in cube      \\
    Cube    & $d = 2 \ldots 4$ & $n = 10 \ldots 15$    & $360$    & Random in cube      \\
    Iowa  & $d = 3 \ldots 5$ & $n = 10$              & $30$     & Random in cube      \\
    Sausage & $d = 2 \ldots 5$ & $n = 10 \ldots 15$    & $24$     & Simplex sequence    \\
    \bottomrule
  \end{tabular}
  \caption[Test sets used to test performance]{The table shows the tests sets,
    their dimensions, number of terminals, number of instances and type of instances,
    which has been used to test the performance of the implementation.\label{tab:test-sets}}
\end{table}

The sets \textit{Carioca} and \textit{Cube} have been pruned. This has been done
due to the sheer size of these sets. Even with these sets pruned, running all of
the sets for all of the methods took a little more than a week in which a
quad-core computer ran at all hours of the day. Furthermore all runs were set up such that
they would halt if more than $12$ hours passed, and it was then concluded
infeasible to solve that specific instance using the given method. How many
instances completed before the time limit can be seen in \cref{tab:set-success}.

A few initial test runs showed that, especially \texttt{SimpleSort} but also
occasionally \texttt{SmithNewSort}, could solve instances for $n=17$ within the
$12$ hour limit. Time-wise it was however still infeasible to perform a proper
test with these instance sizes. Thus the new implementation solves instances
about the same size as \textcite{fonseca2014}.

The data collected from the runs have been used to compare the speed (i.e.\
run-time), the number of iterations, and the number of trees optimized. The
results are presented and described in the two sections below.

\begin{table}[htbp]
  \centering
  \begin{tabular}{cccccc}
    \toprule
            & \multicolumn{5}{c}{Method}                             \\
    Set     & \texttt{Simple} 
            & \texttt{SimpleSort}
            & \texttt{SmithNew} 
            & \texttt{SmithNewSort}
            & \texttt{SmithOld}                                      \\
    \cmidrule(r){1-1}\cmidrule(l){2-6}
    Carioca & $81/90$  & $89/90$  & $73/90$   & $87/90$  & $76/90$   \\
    Cube    & $\checkmark$ & $\checkmark$ & $352/360$ & $\checkmark$ & $356/360$ \\
    Iowa  & $\checkmark$ & $\checkmark$ & $\checkmark$  & $\checkmark$ & $\checkmark$  \\
    Sausage & $22/24$  & $23/24$  & $18/24$   & $22/24$  & $21/24$   \\
    \bottomrule
  \end{tabular}
  \caption[Successfull test runs]{The table shows the number of successful
    instances, i.e.\ instances which finished within $12$ hours, of the test
    sets which has been run. A checkmark indicates all instances of the set was
    solved.\label{tab:set-success}}
\end{table}

\subsection{Speed}
\label{sec:speed}

To compare the speed of the new implementation with the implementation by
\textcite{smith1992} box-plots of the run-times for \textit{Carioca},
\textit{Cube} and \textit{Iowa}, have been plotted in
\cref{fig:boxplot-carioca-d3,fig:boxplot-carioca-d4,fig:boxplot-cube-d3,fig:boxplot-cube-d4,fig:boxplot-iowa-n10}.
The y-axis of the box-plots is logarithmic to make the plots manageable. Notice
that
\cref{fig:boxplot-carioca-d3,fig:boxplot-carioca-d4,fig:boxplot-cube-d3,fig:boxplot-cube-d4}
have the number of terminals on the x-axis and are for fixed dimensions, whereas
\cref{fig:boxplot-iowa-n10} has the dimensions on the x-axis and is the for a
fixed number of terminals. This is simply due to the fact that \textit{Iowa}
only contains $n=10$ instances, whereas the other sets contain several instances
of different dimensions and number of terminals. This also illustrates that the
number of dimensions affects the run-time, but not nearly as much as the number
of terminals does.

As can be seen in the figures the running time of \texttt{SmithNew} (implemented
in Go) is in general a bit higher than that of \texttt{SmithOld} (implemented in
C), whereas the new analytical solution \texttt{Simple} (implemented in Go) in
general is lower. The reason for the higher running time of \texttt{SmithNew} is
probably due to the fact that the implementation is done in Go instead of C as
the original implementation. Unfortunately we are therefore not really able to
say anything about the performance of the new data structure for topologies
(described in \cref{sec:building-topologies}) being better of worse than the
original implementation. It is however interesting to see that the analytical
solution seems to have better running times than not only \texttt{SmithNew}, but
also \texttt{SmithOld}, as this suggests that an implementation of this method
in a more efficient language, such as C, would yield even better running
times\footnote{Thus in retrospect the new implementation should maybe have been
  done in C, especially as the concurrency of Go. A potential scheme for
  concurrency is described and discussed in \cref{sec:concurrency}.}. Further
this seems to debunk the claim by \textcite{smith1992} that a simple iteration
would converge slower, at least speed-wise. Of course we still need to keep in
mind the fact that \texttt{Simple} have resulted in some sub-optimal trees. It
however seems unlikely, when looking at the percent of sub-optimal results that
this should skew the results so much that this would be changed.

\begin{figure}[htbp]
  \centering
  \includegraphics[width=\textwidth]{gfx/boxplots/plot_nvst_boxplot_d3_Carioca_1}
  \caption[Box-plot for Carioca with $d = 3$]{Box-plot showing the run-times for
    the Carioca set with $d = 3$.\label{fig:boxplot-carioca-d3}}
\end{figure}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=\textwidth]{gfx/boxplots/plot_nvst_boxplot_d4_Carioca_1}
  \caption[Box-plot for Carioca with $d = 4$]{Box-plot showing the run-times for
    the Carioca set with $d = 4$.\label{fig:boxplot-carioca-d4}}
\end{figure}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=\textwidth]{gfx/boxplots/plot_nvst_boxplot_d3_Cube_1}
  \caption[Box-plot for Cube with $d = 3$]{Box-plot showing the run-times for
    the Cube set with $d = 3$.\label{fig:boxplot-cube-d3}}
\end{figure}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=\textwidth]{gfx/boxplots/plot_nvst_boxplot_d4_Cube_1}
  \caption[Box-plot for Cube with $d = 4$]{Box-plot showing the run-times for
    the Cube set with $d = 4$.\label{fig:boxplot-cube-d4}}
\end{figure}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=\textwidth]{gfx/boxplots/plot_nvst_boxplot_n10_Iowa_1}
  \caption[Box-plot for Iowa with $n = 10$]{Box-plot showing the run-times for
    the Iowa set with $n = 10$.\label{fig:boxplot-iowa-n10}}
\end{figure}

As can furthermore be seen in the figures, the run-time of both methods drop
significantly when using terminal sorting (\texttt{SmithNewSort} and
\texttt{SimpleSort}). In almost all cases, no matter the number of terminals or dimensions, is
the third quartile of for the methods with terminal sorting below the first
quartile for the respective method without terminal sorting. Furthermore in most
cases is the third quartile of \texttt{SimpleSort} below the first quartile of
\texttt{SmithOld}, and the run-times for \texttt{SmithNewSort} are better than
or comparable to that of \texttt{SmithOld}.

The reason that the \textit{Carioca} and \textit{Iowa} for $d=5$ and
\textit{Cube} for $d = 2$ have not been plotted is, both that they show the same
situation, but also that $d=2$ is so small that they go below the graph, and
would require a change of y-axis, and $d=5$ has a bit too few solved
instances for $n=15$ for it to be quite as reliable.

\subsection{Trees and Iterations}
\label{sec:trees-iterations}

Apart from the actual run-time of the implementation it is also worth measuring
the number of optimization iterations one runs when solving an instance, and the
number of trees optimized.

The number of optimization iterations is counted as the number of times the
optimization function is called when solving an instance, i.e.\ every time
perform an optimization (no matter the number of terminals in the topology) we
increment the number of optimization iterations with one.

The number of trees optimized is counted as the sum of trees which is optimized
at least once. As described earlier we may have some trees which are never
optimized at all. We may also have trees which are optimized more than once
(this is the most likely, as a single tree normally requires several
optimization iterations). Every time we optimize a tree which we have not
optimized before (no matter the number of terminals in the topology) we
increment the number of optimized trees by one.

\begin{table}[htbp]
  \centering
  \input{gfx/tables/tree-ratio}
  \caption[Tree-exploration ratio for Sausage]{The table shows the ratio of
    trees optimized in relation to \texttt{OldSmith}. The number of trees is
    measured such that if a topology vector has been optimized at least once,
    then the number of optimized trees is optimized by one. Topologies that are
    pruned before any optimization has taken place is not counted, and any
    topology can at max be counted once. The data shown are from the Sausage
    set. An empty field means that either the instance for that method or the
    instance for \texttt{SmithOld} could not be solved within the time
    limit.\label{tab:trees-sausage-ratio}}
\end{table}

\cref{tab:trees-sausage-ratio} shows the number of trees optimized, as a ratio
of the trees optimized by \texttt{SmithOld}\footnote{So if e.g.\
  \texttt{SmithOld} has optimized $100$ trees and \texttt{Simple} has optimized
  $56$ trees, the ratio for \texttt{Simple} would be $56/100 = 0.56$.}, and
\cref{tab:iterations-sausage-ratio} shows the number of iterations as a ratio of
the iterations used by \texttt{SmithOld}. Both of these tables are based on the
data collected for the data set \texttt{Sausage}. This set is used as there is one instance for each combination
of $n$ and $d$ making it easy to calculate the ratios.

As can be seen by the first table \texttt{Simple} and \texttt{SmithNew},
optimizes more trees than \texttt{SmithOld}. Especially \texttt{SmithNew} in
some instances optimizes up to three times as many trees. This is of course not
very desirable and the exact reason for this is unfortunately unknown.

There seems to be several possibilities for the observed behavior. The first
possibility is that the counting of the trees has a bug in either the new or original
implementation, or that it does not count them in the same way. After further
inspection of the source code, this however does not seem to be the case. The
second possibility is that there is a bug somewhere in the new implementation,
causing it to not prune as many trees as the original implementation. This seems
a more likely reason, but inspection of the source code again failed to reveal
such a problem. This could however be tied together with the if-clauses
described in \cref{sec:correctness} and the variable described in
\cref{sec:scale}. The original implementation uses the variable \textit{SCALE} in the
calculation of the initial placement for new Steiner points. If this causes the
Steiner points to have better initial placements it could be thought that the
if-clauses of the main loop were able to prune earlier.

A third possibility, and probably the must likely, is that the way in which
topologies are split in the new implementation is the cause of the extra
iterations. As described before, when splitting a topology in the new
implementation we re-use the existing coordinates for the Steiner points already
in the topology. When we do this a large portion of the tree is at a low error.
This in turn can cause \citeauthor{smith1992}'s iteration to converge very
slowly. This could therefore be the cause for the extra iterations for
\texttt{SmithNew}, but should not affect \texttt{Simple}. For \texttt{Simple} a
likely explanation is, that the iteration may indeed just require more
iterations to converge as is postulated by \textcite{smith1992}, but because
each iteration is much lighter computationally they are done quicker and thus we
still see better run-times.

As observed with the speed of the program, the number of trees optimized in
general also drops drastically when sorting the terminals (\texttt{SimpleSort}
and \texttt{SmithNewSort}). In all cases the ratio becomes smaller than the
unsorted counter-part, and in most cases it also becomes a lot smaller than
\texttt{SmithOld}.

\begin{table}[htbp]
  \centering
  \input{gfx/tables/iteration-ratio}
  \caption[Iteration ratio for Sausage]{The table shows the ratio of iterations
    in relation to \texttt{SmithOld} for the Sausage set. The structure is as
    in \cref{tab:trees-sausage-ratio}. However an iteration means every time we
    perform an optimization, i.e.\ a tree can contribute many times to this if
    we run the iteration for multiple times on the tree (which we most likely
    do).\label{tab:iterations-sausage-ratio}}
\end{table}

Looking at \cref{tab:iterations-sausage-ratio} we see more or less the same
situation, as in \cref{tab:trees-sausage-ratio}. A column worth noting however,
is the one for \texttt{Simple}. As can be seen in the first table, the ratio for
the number of optimized trees in general is slightly above $1$. However the
ratio for iterations is in general below $0.5$. This means that \texttt{Simple}
is a lot quicker at reaching a low error and thus stopping to optimize the
trees. This could mean that the analytical solution converges a lot faster than
\citeauthor{smith1992}'s iteration. However again we need to remember the
results from \cref{sec:correctness}, which means that we need to be a bit
cautious with such a conclusion. But considering that the ratio is consistently lower
for the number of iterations\footnote{Except for a single outlier}, and thus is
seems unlikely that the result is solely due to sub-optimality, as described
earlier.

A thing worth noticing is that the higher run-times for \texttt{SmithNew} (and
partly \texttt{SmithNewSort}) observed in the previous section make a lot more
sense when observing the ratios for trees and iterations. Thus it is very
possible, that if one could bring down these numbers the new implementation
would have faster run-times than \texttt{SmithOld} all around.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../../main"
%%% End:
